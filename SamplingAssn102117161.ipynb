{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMnqyEXOzT9Uxq1AmMKthsZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cdr0101/SamplingAssn102117161/blob/main/SamplingAssn102117161.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SAMPLING ASSIGNMENT**\n",
        "\n",
        "**Submitted by: CHELSI**\n",
        "\n",
        "**Roll no.: 102117161**\n",
        "\n",
        "**Group: 3CS6**"
      ],
      "metadata": {
        "id": "ZSiaAbkmKKVr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the required libraries"
      ],
      "metadata": {
        "id": "OQfAAoZvIylD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, KFold\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "tjsQSptlEegY"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the data and splitting it after balancing using SMOTE technique."
      ],
      "metadata": {
        "id": "joC_B-NoI4tW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading dataset\n",
        "data_df = pd.read_csv('/content/Creditcard_data.csv')\n",
        "\n",
        "# Separating features (to X) and target (to y)\n",
        "X = data_df.drop('Class', axis=1)\n",
        "y = data_df['Class']\n",
        "\n",
        "# Applying smote technique to balance the data\n",
        "smote = SMOTE(random_state=42)\n",
        "X_balanced, y_balanced = smote.fit_resample(X, y)\n",
        "\n",
        "# Spliting into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "UI6fRYxKEh4B"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the models and sampling techniques to be used"
      ],
      "metadata": {
        "id": "e6s21HSUJLQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    'Decision Tree': DecisionTreeClassifier(),\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'XGBoost': XGBClassifier(),\n",
        "    'Logistic Regression': LogisticRegression(),\n",
        "    'KNN': KNeighborsClassifier()\n",
        "}\n",
        "\n",
        "sampling_techniques = {\n",
        "    'Simple Random': 'simpleRandom',\n",
        "    'Systematic': 'systematic',\n",
        "    'Stratified': 'stratified',\n",
        "    'Cluster': 'cluster',\n",
        "    'Cross Validation': 'crossValidation'\n",
        "}"
      ],
      "metadata": {
        "id": "o_TgiSRbEjnX"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementing sampling and fitting the models to each sample"
      ],
      "metadata": {
        "id": "UwPCXG60JUKC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "for model_name, model in models.items():\n",
        "    model_results = []\n",
        "    for technique_name, technique in sampling_techniques.items():\n",
        "        # Sampling the data based on technique to be used\n",
        "        if technique == 'simpleRandom':\n",
        "            X_sampled, y_sampled = X_train, y_train\n",
        "        elif technique == 'systematic':\n",
        "            # Implementing systematic sampling by selecting every nth item\n",
        "            n = 5\n",
        "            X_sampled, _, y_sampled, _ = train_test_split(X_train, y_train, test_size=1-(1/n))\n",
        "        elif technique == 'stratified': # stratified sampling\n",
        "            strat_split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
        "            for train_index, _ in strat_split.split(X_train, y_train):\n",
        "                X_sampled, y_sampled = X_train.iloc[train_index], y_train.iloc[train_index]\n",
        "        elif technique == 'cluster':\n",
        "            # Implementing cluster sampling\n",
        "            # Assuming each row represents a cluster, sample clusters instead of individual data points\n",
        "            cluster_indices = [i for i in range(0, len(X_train), 50)]  # Assuming clusters of 50 rows each\n",
        "            X_sampled = X_train.iloc[cluster_indices]\n",
        "            y_sampled = y_train.iloc[cluster_indices]\n",
        "        elif technique == 'crossValidation': # Cross validation sampling\n",
        "            kf = KFold(n_splits=5, random_state=0, shuffle=True)\n",
        "            for _, test_index in kf.split(X_train, y_train):\n",
        "                X_sampled, y_sampled = X_train.iloc[test_index], y_train.iloc[test_index]\n",
        "\n",
        "        model.fit(X_sampled, y_sampled)\n",
        "\n",
        "        y_pred = model.predict(X_test) # Making predictions\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        model_results.append(accuracy*100)\n",
        "\n",
        "    results[model_name] = model_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuvfyz0TEc77",
        "outputId": "d225db34-8361-473b-b1da-bfe0c501e2e7"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accuracy Table**"
      ],
      "metadata": {
        "id": "uTQkctg_Jg-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = pd.DataFrame(results, index=sampling_techniques.keys()).transpose()\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7myyriz9ElUw",
        "outputId": "f6c703c6-c3c8-4b90-df5e-b001a3b77419"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     Simple Random  Systematic  Stratified    Cluster  \\\n",
            "Decision Tree            98.366013   90.196078   98.039216  78.758170   \n",
            "Random Forest            99.019608   96.405229   99.346405  80.392157   \n",
            "XGBoost                  98.692810   92.156863   98.366013  75.163399   \n",
            "Logistic Regression      90.522876   89.542484   89.542484  73.856209   \n",
            "KNN                      83.333333   70.588235   81.699346  54.248366   \n",
            "\n",
            "                     Cross Validation  \n",
            "Decision Tree               88.562092  \n",
            "Random Forest               98.039216  \n",
            "XGBoost                     93.464052  \n",
            "Logistic Regression         88.888889  \n",
            "KNN                         68.300654  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation: Maximum accuracy has been achieved corresponding to STRATIFIED SAMPLING AND RANDOM FOREST MODEL. (99.346405%)**"
      ],
      "metadata": {
        "id": "bY5CsghDJjp6"
      }
    }
  ]
}